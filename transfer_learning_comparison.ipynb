{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Transfer Learning Comparison: AlexNet, VGGNet, and ResNet on Custom Dataset\n",
    "\n",
    "This script compares feature extraction vs fine-tuning approaches for three popular\n",
    "CNN architectures (AlexNet, VGG16, ResNet18) on a custom image classification task.\n",
    "\n",
    "Author: VShulgin\n",
    "Date: 2022-08-13\n",
    "\"\"\"\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import optim, nn\n",
    "from torchvision import transforms, models\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from typing import Dict, List, Tuple\n",
    "import time\n",
    "import os\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "def set_seed(seed: int = 42) -> None:\n",
    "    \"\"\"\n",
    "    Set random seeds for reproducibility across all libraries.\n",
    "    \n",
    "    Args:\n",
    "        seed: Random seed value\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "# Check device availability\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "def prepare_data(data_path: str = 'images', \n",
    "                batch_size: int = 32,\n",
    "                train_ratio: float = 0.8) -> Tuple[DataLoader, DataLoader, List[str]]:\n",
    "    \"\"\"\n",
    "    Prepare and load image data with appropriate transformations.\n",
    "    \n",
    "    Args:\n",
    "        data_path: Path to the image dataset\n",
    "        batch_size: Batch size for data loaders\n",
    "        train_ratio: Ratio of training data\n",
    "        \n",
    "    Returns:\n",
    "        Tuple of (train_loader, test_loader, class_names)\n",
    "    \"\"\"\n",
    "    # Data augmentation for training, simple transformation for testing\n",
    "    train_transform = transforms.Compose([\n",
    "        transforms.Resize((256, 256)),\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomRotation(10),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], \n",
    "                           std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    test_transform = transforms.Compose([\n",
    "        transforms.Resize((256, 256)),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], \n",
    "                           std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    # Load dataset\n",
    "    train_dataset = ImageFolder(data_path, transform=train_transform)\n",
    "    test_dataset = ImageFolder(data_path, transform=test_transform)\n",
    "    \n",
    "    # Split dataset\n",
    "    train_size = int(train_ratio * len(train_dataset))\n",
    "    test_size = len(train_dataset) - train_size\n",
    "    \n",
    "    train_subset, test_subset = random_split(\n",
    "        train_dataset, [train_size, test_size]\n",
    "    )\n",
    "    \n",
    "    # Create data loaders\n",
    "    train_loader = DataLoader(\n",
    "        train_subset, \n",
    "        batch_size=batch_size, \n",
    "        shuffle=True,\n",
    "        num_workers=2,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    \n",
    "    test_loader = DataLoader(\n",
    "        test_subset, \n",
    "        batch_size=batch_size, \n",
    "        shuffle=False,\n",
    "        num_workers=2,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    \n",
    "    return train_loader, test_loader, train_dataset.classes\n",
    "\n",
    "def visualize_samples(data_loader: DataLoader, \n",
    "                     class_names: List[str], \n",
    "                     num_samples: int = 9) -> None:\n",
    "    \"\"\"\n",
    "    Visualize sample images from the dataset.\n",
    "    \n",
    "    Args:\n",
    "        data_loader: DataLoader containing images\n",
    "        class_names: List of class names\n",
    "        num_samples: Number of samples to display\n",
    "    \"\"\"\n",
    "    images, labels = next(iter(data_loader))\n",
    "    \n",
    "    fig, axes = plt.subplots(3, 3, figsize=(12, 12))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for i, ax in enumerate(axes):\n",
    "        if i < num_samples:\n",
    "            # Denormalize image\n",
    "            img = images[i].numpy().transpose(1, 2, 0)\n",
    "            mean = np.array([0.485, 0.456, 0.406])\n",
    "            std = np.array([0.229, 0.224, 0.225])\n",
    "            img = std * img + mean\n",
    "            img = np.clip(img, 0, 1)\n",
    "            \n",
    "            ax.imshow(img)\n",
    "            ax.set_title(f'Class: {class_names[labels[i]]}')\n",
    "            ax.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('dataset_samples.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "def create_model(model_name: str, \n",
    "                num_classes: int, \n",
    "                feature_extraction: bool = True) -> Tuple[nn.Module, List]:\n",
    "    \"\"\"\n",
    "    Create a pretrained model with modified classifier.\n",
    "    \n",
    "    Args:\n",
    "        model_name: Name of the model ('alexnet', 'vgg16', 'resnet18')\n",
    "        num_classes: Number of output classes\n",
    "        feature_extraction: Whether to freeze feature extractor weights\n",
    "        \n",
    "    Returns:\n",
    "        Tuple of (model, parameters_to_train)\n",
    "    \"\"\"\n",
    "    if model_name.lower() == 'alexnet':\n",
    "        model = models.alexnet(weights=models.AlexNet_Weights.IMAGENET1K_V1)\n",
    "        if feature_extraction:\n",
    "            for param in model.features.parameters():\n",
    "                param.requires_grad = False\n",
    "        model.classifier[6] = nn.Linear(model.classifier[6].in_features, num_classes)\n",
    "        params_to_train = model.classifier[6].parameters()\n",
    "        \n",
    "    elif model_name.lower() == 'vgg16':\n",
    "        model = models.vgg16(weights=models.VGG16_Weights.IMAGENET1K_V1)\n",
    "        if feature_extraction:\n",
    "            for param in model.features.parameters():\n",
    "                param.requires_grad = False\n",
    "        model.classifier[6] = nn.Linear(model.classifier[6].in_features, num_classes)\n",
    "        params_to_train = model.classifier[6].parameters()\n",
    "        \n",
    "    elif model_name.lower() == 'resnet18':\n",
    "        model = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n",
    "        if feature_extraction:\n",
    "            for param in model.parameters():\n",
    "                param.requires_grad = False\n",
    "        num_ftrs = model.fc.in_features\n",
    "        model.fc = nn.Linear(num_ftrs, num_classes)\n",
    "        params_to_train = model.fc.parameters()\n",
    "        \n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported model: {model_name}\")\n",
    "    \n",
    "    return model, list(params_to_train)\n",
    "\n",
    "def train_model(model: nn.Module, \n",
    "               train_loader: DataLoader, \n",
    "               test_loader: DataLoader, \n",
    "               criterion: nn.Module,\n",
    "               optimizer: optim.Optimizer,\n",
    "               scheduler: optim.lr_scheduler._LRScheduler,\n",
    "               epochs: int = 10,\n",
    "               model_name: str = \"Model\") -> Tuple[List[float], List[float], List[float]]:\n",
    "    \"\"\"\n",
    "    Train a model and return training history.\n",
    "    \n",
    "    Args:\n",
    "        model: Neural network model\n",
    "        train_loader: Training data loader\n",
    "        test_loader: Test data loader\n",
    "        criterion: Loss function\n",
    "        optimizer: Optimizer\n",
    "        scheduler: Learning rate scheduler\n",
    "        epochs: Number of training epochs\n",
    "        model_name: Name of the model for printing\n",
    "        \n",
    "    Returns:\n",
    "        Tuple of (train_losses, test_losses, test_accuracies)\n",
    "    \"\"\"\n",
    "    model = model.to(device)\n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "    test_accuracies = []\n",
    "    \n",
    "    print(f\"\\nTraining {model_name}...\")\n",
    "    print(\"-\" * 60)\n",
    "    start_time = time.time()\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "        \n",
    "        train_loss = running_loss / len(train_loader)\n",
    "        train_accuracy = 100. * correct / total\n",
    "        train_losses.append(train_loss)\n",
    "        \n",
    "        # Evaluation phase\n",
    "        model.eval()\n",
    "        test_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for images, labels in test_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                test_loss += loss.item()\n",
    "                \n",
    "                _, predicted = outputs.max(1)\n",
    "                total += labels.size(0)\n",
    "                correct += predicted.eq(labels).sum().item()\n",
    "        \n",
    "        test_loss /= len(test_loader)\n",
    "        test_accuracy = 100. * correct / total\n",
    "        test_losses.append(test_loss)\n",
    "        test_accuracies.append(test_accuracy)\n",
    "        \n",
    "        scheduler.step()\n",
    "        \n",
    "        print(f'Epoch [{epoch+1:2d}/{epochs}] | '\n",
    "              f'Train Loss: {train_loss:.4f} | '\n",
    "              f'Test Loss: {test_loss:.4f} | '\n",
    "              f'Test Acc: {test_accuracy:.2f}%')\n",
    "    \n",
    "    training_time = time.time() - start_time\n",
    "    print(f\"{model_name} training completed in {training_time:.2f} seconds\")\n",
    "    print(f\"Final Test Accuracy: {test_accuracies[-1]:.2f}%\")\n",
    "    \n",
    "    return train_losses, test_losses, test_accuracies\n",
    "\n",
    "def plot_comparison(results: Dict[str, Dict[str, Tuple[List[float], List[float], List[float]]]]) -> None:\n",
    "    \"\"\"\n",
    "    Plot comparison results between different models and approaches.\n",
    "    \n",
    "    Args:\n",
    "        results: Dictionary containing training results\n",
    "    \"\"\"\n",
    "    # Plot feature extraction results\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "    \n",
    "    # Feature Extraction - Loss\n",
    "    for model_name, metrics in results.items():\n",
    "        train_loss, test_loss, test_acc = metrics[\"Feature Extraction\"]\n",
    "        axes[0, 0].plot(train_loss, label=f'{model_name}', linewidth=2)\n",
    "    axes[0, 0].set_title('Feature Extraction - Training Loss')\n",
    "    axes[0, 0].set_xlabel('Epoch')\n",
    "    axes[0, 0].set_ylabel('Loss')\n",
    "    axes[0, 0].legend()\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Feature Extraction - Accuracy\n",
    "    for model_name, metrics in results.items():\n",
    "        train_loss, test_loss, test_acc = metrics[\"Feature Extraction\"]\n",
    "        axes[0, 1].plot(test_acc, label=f'{model_name}', linewidth=2)\n",
    "    axes[0, 1].set_title('Feature Extraction - Test Accuracy')\n",
    "    axes[0, 1].set_xlabel('Epoch')\n",
    "    axes[0, 1].set_ylabel('Accuracy (%)')\n",
    "    axes[0, 1].legend()\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Fine-tuning - Loss\n",
    "    for model_name, metrics in results.items():\n",
    "        train_loss, test_loss, test_acc = metrics[\"Fine-tuning\"]\n",
    "        axes[1, 0].plot(train_loss, label=f'{model_name}', linewidth=2)\n",
    "    axes[1, 0].set_title('Fine-tuning - Training Loss')\n",
    "    axes[1, 0].set_xlabel('Epoch')\n",
    "    axes[1, 0].set_ylabel('Loss')\n",
    "    axes[1, 0].legend()\n",
    "    axes[1, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Fine-tuning - Accuracy\n",
    "    for model_name, metrics in results.items():\n",
    "        train_loss, test_loss, test_acc = metrics[\"Fine-tuning\"]\n",
    "        axes[1, 1].plot(test_acc, label=f'{model_name}', linewidth=2)\n",
    "    axes[1, 1].set_title('Fine-tuning - Test Accuracy')\n",
    "    axes[1, 1].set_xlabel('Epoch')\n",
    "    axes[1, 1].set_ylabel('Accuracy (%)')\n",
    "    axes[1, 1].legend()\n",
    "    axes[1, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('transfer_learning_comparison.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    # Individual model comparisons\n",
    "    for model_name in results.keys():\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "        \n",
    "        # Training loss comparison\n",
    "        fe_train_loss, fe_test_loss, fe_test_acc = results[model_name][\"Feature Extraction\"]\n",
    "        ft_train_loss, ft_test_loss, ft_test_acc = results[model_name][\"Fine-tuning\"]\n",
    "        \n",
    "        axes[0].plot(fe_train_loss, label='Feature Extraction', linewidth=2)\n",
    "        axes[0].plot(ft_train_loss, label='Fine-tuning', linewidth=2)\n",
    "        axes[0].set_title(f'{model_name} - Training Loss Comparison')\n",
    "        axes[0].set_xlabel('Epoch')\n",
    "        axes[0].set_ylabel('Loss')\n",
    "        axes[0].legend()\n",
    "        axes[0].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Test accuracy comparison\n",
    "        axes[1].plot(fe_test_acc, label='Feature Extraction', linewidth=2)\n",
    "        axes[1].plot(ft_test_acc, label='Fine-tuning', linewidth=2)\n",
    "        axes[1].set_title(f'{model_name} - Test Accuracy Comparison')\n",
    "        axes[1].set_xlabel('Epoch')\n",
    "        axes[1].set_ylabel('Accuracy (%)')\n",
    "        axes[1].legend()\n",
    "        axes[1].grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'{model_name.lower()}_comparison.png', dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function to run the transfer learning comparison.\"\"\"\n",
    "    # Prepare data\n",
    "    print(\"Loading and preparing data...\")\n",
    "    train_loader, test_loader, class_names = prepare_data(\n",
    "        data_path='images', \n",
    "        batch_size=32,\n",
    "        train_ratio=0.8\n",
    "    )\n",
    "    \n",
    "    print(f\"Number of classes: {len(class_names)}\")\n",
    "    print(f\"Classes: {class_names}\")\n",
    "    \n",
    "    # Visualize samples\n",
    "    print(\"Visualizing sample images...\")\n",
    "    visualize_samples(train_loader, class_names)\n",
    "    \n",
    "    # Initialize results dictionary\n",
    "    results = {\n",
    "        \"AlexNet\": {},\n",
    "        \"VGG16\": {},\n",
    "        \"ResNet18\": {}\n",
    "    }\n",
    "    \n",
    "    # Training parameters\n",
    "    epochs = 15\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    # Test both approaches for each model\n",
    "    models_to_test = [\"AlexNet\", \"VGG16\", \"ResNet18\"]\n",
    "    approaches = [\"Feature Extraction\", \"Fine-tuning\"]\n",
    "    \n",
    "    for model_name in models_to_test:\n",
    "        for approach in approaches:\n",
    "            feature_extraction = (approach == \"Feature Extraction\")\n",
    "            \n",
    "            print(f\"\\n{approach} with {model_name}\")\n",
    "            print(\"=\" * 50)\n",
    "            \n",
    "            # Create model\n",
    "            model, params_to_train = create_model(\n",
    "                model_name, \n",
    "                len(class_names), \n",
    "                feature_extraction=feature_extraction\n",
    "            )\n",
    "            \n",
    "            # Set up optimizer and scheduler\n",
    "            if feature_extraction:\n",
    "                optimizer = optim.Adam(params_to_train, lr=0.001, weight_decay=1e-4)\n",
    "            else:\n",
    "                optimizer = optim.Adam(model.parameters(), lr=0.0001, weight_decay=1e-4)\n",
    "            \n",
    "            scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "            \n",
    "            # Train model\n",
    "            train_losses, test_losses, test_accuracies = train_model(\n",
    "                model, train_loader, test_loader, criterion,\n",
    "                optimizer, scheduler, epochs=epochs,\n",
    "                model_name=f\"{model_name} ({approach})\"\n",
    "            )\n",
    "            \n",
    "            results[model_name][approach] = (train_losses, test_losses, test_accuracies)\n",
    "    \n",
    "    # Plot results\n",
    "    print(\"\\nPlotting comparison results...\")\n",
    "    plot_comparison(results)\n",
    "    \n",
    "    # Print final results\n",
    "    print(\"\\nFinal Results Comparison:\")\n",
    "    print(\"=\" * 60)\n",
    "    for model_name in results.keys():\n",
    "        for approach in approaches:\n",
    "            train_loss, test_loss, test_acc = results[model_name][approach]\n",
    "            print(f\"{model_name:10} {approach:20}: \"\n",
    "                  f\"Final Test Acc = {test_acc[-1]:6.2f}% | \"\n",
    "                  f\"Final Loss = {test_loss[-1]:.4f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
